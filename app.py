import os
import time
import tempfile
from typing import Optional, Tuple, List, Dict

import streamlit as st
from google import genai
from pypdf import PdfReader


# ============================================================
# 0) App Config
# ============================================================
st.set_page_config(
    page_title="KIHS ë³´ê³ ì„œ í•™ìŠµí˜• ë¶„ì„ê¸° (ë°ëª¨)",
    page_icon="ğŸ’§",
    layout="wide",
)

st.title("ğŸ’§ KIHS (í•œêµ­ìˆ˜ìì›ì¡°ì‚¬ê¸°ìˆ ì›) ë³´ê³ ì„œ í•™ìŠµí˜• ë¶„ì„ê¸° (Demo)")
st.caption("PDF ìš”ì•½ Â· êµìœ¡í˜• Q&A Â· ì¶”ê°€ ì§ˆì˜(ëŒ€í™”) â€” Gemini + ë¡œì»¬ íŒŒì‹± ìš°ì„ (ì•ˆì •)")

st.markdown(
    """
- ë³¸ ì•±ì€ **ë°ëª¨**ì…ë‹ˆë‹¤. ê²°ê³¼ëŠ” ì°¸ê³ ìš©ì´ë©°, ì›ë¬¸ ê·¼ê±° ë²”ìœ„ ë‚´ì—ì„œë§Œ í•´ì„í•´ì•¼ í•©ë‹ˆë‹¤.
- **API ì•ˆì •ì„±**ì„ ìœ„í•´ ë¨¼ì € PDFë¥¼ ë¡œì»¬ì—ì„œ í…ìŠ¤íŠ¸ë¡œ ì¶”ì¶œí•œ ë’¤, í…ìŠ¤íŠ¸ ê¸°ë°˜ìœ¼ë¡œ Geminiì— ì§ˆì˜í•©ë‹ˆë‹¤.
- ìŠ¤ìº” PDF ë“± í…ìŠ¤íŠ¸ ì¶”ì¶œì´ ë¶€ì¡±í•œ ê²½ìš°ì—ë§Œ(ì„ íƒ) íŒŒì¼ ì—…ë¡œë“œ ë°©ì‹ìœ¼ë¡œ **fallback**í•©ë‹ˆë‹¤.
"""
)

# ============================================================
# 1) Prompt Definitions (ì‚¬ì „ ì •ì˜)
# ============================================================

PROMPT_COMMON_RULES = """
[ê³µí†µ ê·œì¹™]
- ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”.
- ë‹¹ì‹ ì€ 'KIHS(í•œêµ­ìˆ˜ìì›ì¡°ì‚¬ê¸°ìˆ ì›) ë³´ê³ ì„œ ê¸°ë°˜ êµìœ¡/ë¶„ì„ íŠœí„°'ì…ë‹ˆë‹¤.
- ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ ë§Œë“¤ì§€ ë§ê³ , ë¶ˆí™•ì‹¤í•˜ë©´ 'ë¬¸ì„œì—ì„œ í™•ì¸ ë¶ˆê°€'ë¼ê³  ëª…ì‹œí•˜ì„¸ìš”.
- ê°€ëŠ¥í•œ ê²½ìš°, ê·¼ê±°ê°€ ë˜ëŠ” ë¬¸ì„œ í‘œí˜„ì„ 1~2ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•´ í•¨ê»˜ ì œì‹œí•˜ì„¸ìš”(ì§ì ‘ ì¸ìš©ì€ 1ë¬¸ì¥ ì´ë‚´).
- ê³¼ì¥ ì—†ì´ ê°„ê²°í•˜ê³  ë‹¨ì •í•œ ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.
"""

PROMPT_OPTIONS = """
[ì˜µì…˜]
- í†¤: ê³µê³µê¸°ê´€ ë³´ê³ ì„œ ìŠ¤íƒ€ì¼(ì°¨ë¶„, ë‹¨ì •, ê³¼ì¥ ì—†ìŒ) + í•™ìŠµì ì¹œí™”(í•µì‹¬â†’ì„¤ëª…â†’ì •ë¦¬)
- ë…ì: ìˆ˜ìì›/ë¬¼ê´€ë¦¬ ë¶„ì•¼ ì‹¤ë¬´ì ë° ì—°êµ¬ì(ì´ˆì¤‘ê¸‰ í¬í•¨)
- ê¸ˆì§€: í™ë³´ì„± í‘œí˜„, ê°ì •ì  í‘œí˜„, ê·¼ê±° ì—†ëŠ” ë‹¨ì •, ê³¼ë„í•œ ìƒìƒ
- ìš©ì–´: í•œêµ­ì–´ ìš©ì–´ ìš°ì„ (ì˜ˆ: water treatment plant=ì •ìˆ˜ì¥)
"""

PROMPT_SECTIONS_SUMMARY = """
[ìš”ì•½ ë¦¬í¬íŠ¸ ì¶œë ¥ ì„¹ì…˜]
1) í•µì‹¬ ìš”ì•½ (6ì¤„ ì´ë‚´)
2) ì—°êµ¬ ë°°ê²½/ë¬¸ì œì •ì˜ (bullet 3~6ê°œ)
3) ë°©ë²•/ë°ì´í„°/ëŒ€ìƒ (bullet 3~8ê°œ) â€” ë¬¸ì„œì—ì„œ í™•ì¸ë˜ëŠ” ë²”ìœ„
4) ì£¼ìš” ê²°ê³¼/ì„±ê³¼ (bullet 5~12ê°œ, ê°€ëŠ¥í•˜ë©´ ìˆ˜ì¹˜ í¬í•¨)
5) ê²°ë¡  (bullet 3~6ê°œ)
6) ì •ì±… ì‹œì‚¬ì  (3~6ê°œ, ì‹¤í–‰í˜•)
7) ê¸°ìˆ  ì‹œì‚¬ì  (3~6ê°œ, ì‹¤í–‰í˜•)
8) í•œê³„/ë¦¬ìŠ¤í¬/ì „ì œ (bullet 3~8ê°œ)
9) ë‹¤ìŒ ë‹¨ê³„/ì¶”ê°€ ì—°êµ¬ ì§ˆë¬¸ (3~6ê°œ)
"""

PROMPT_EDU_QA_SPEC = """
[êµìœ¡í˜• Q&A ìƒì„± ê·œê²©]
- ì´ {num_q}ê°œ ë¬¸í•­ì„ ìƒì„±.
- í˜•ì‹ì€ ì•„ë˜ ê³ ì •:

Q1. (ì§ˆë¬¸: ê°œë…/ë§¥ë½/ê·¼ê±° ì¤‘ì‹¬)
A1. (ì§§ì€ ë‹µ: 3~5ì¤„)
ê·¼ê±°(ë¬¸ì„œ ê¸°ë°˜): (ë¬¸ì„œì—ì„œ í™•ì¸ë˜ëŠ” ê·¼ê±°ë¥¼ 1~2ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½)
ì¶”ê°€ ì„¤ëª…: (ë°°ê²½ ì„¤ëª…/ì˜¤í•´ ë°©ì§€ 3~6ì¤„)
í•™ìŠµ ì²´í¬: (ì˜ˆ/ì•„ë‹ˆì˜¤ ë˜ëŠ” ë‹¨ë‹µí˜• ì§ˆë¬¸ 1ê°œ)

- ì§ˆë¬¸ ìœ í˜•ì€ ì„ì–´ì„œ êµ¬ì„±:
  (a) í•µì‹¬ ê°œë… ì •ì˜  (b) ì™œ ì¤‘ìš”í•œê°€(ë§¥ë½)  (c) ë°©ë²•/ë°ì´í„°  (d) ê²°ê³¼ í•´ì„  (e) í•œê³„/ë¦¬ìŠ¤í¬  (f) ì‹¤ë¬´ ì ìš©
"""

PROMPT_CHAT_SPEC = """
[ì¶”ê°€ ì§ˆì˜(ëŒ€í™”) ê·œì¹™]
- ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´, ë¬¸ì„œ ê·¼ê±°ë¥¼ ìµœìš°ì„ ìœ¼ë¡œ ë‹µë³€.
- ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ 'ë¬¸ì„œì—ì„œ í™•ì¸ ë¶ˆê°€'ë¡œ ì²˜ë¦¬í•˜ê³ , ëŒ€ì‹  í™•ì¸ì„ ìœ„í•œ ì§ˆë¬¸/ì¶”ê°€ìë£Œë¥¼ ì œì•ˆ.
- ë‹µë³€ êµ¬ì¡°:
  1) ê²°ë¡ (2~4ì¤„)
  2) ê·¼ê±°(ë¬¸ì„œ ê¸°ë°˜ bullet)
  3) ì‹¤ë¬´/ì •ì±…/ê¸°ìˆ  ì‹œì‚¬ì (ê°€ëŠ¥ ì‹œ bullet)
  4) ì¶”ê°€ í™•ì¸ ì§ˆë¬¸(1~3ê°œ)
"""

TASK_SUMMARY = """
[ì‘ì—…]
ì—…ë¡œë“œëœ KIHS ë³´ê³ ì„œ(PDF)ì˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ, ì§€ì •ëœ ì„¹ì…˜ í˜•ì‹ì— ë§ì¶° ìš”ì•½ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•˜ì„¸ìš”.
"""

TASK_EDU_QA = """
[ì‘ì—…]
ì—…ë¡œë“œëœ KIHS ë³´ê³ ì„œ(PDF)ì˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ, í•™ìŠµìš© êµìœ¡í˜• Q&Aë¥¼ ìƒì„±í•˜ì„¸ìš”.
"""

TASK_CHAT = """
[ì‘ì—…]
ì•„ë˜ ì‚¬ìš©ìì˜ ì¶”ê°€ ì§ˆë¬¸ì— ëŒ€í•´, ë¬¸ì„œ ê·¼ê±° ì¤‘ì‹¬ìœ¼ë¡œ ë‹µí•˜ì„¸ìš”.
"""

# ============================================================
# 2) API Key + Client
# ============================================================
def get_api_key() -> Optional[str]:
    key = (st.secrets.get("GOOGLE_API_KEY") or "").strip()
    if key:
        return key
    with st.sidebar:
        st.warning("Secretsì— GOOGLE_API_KEYê°€ ì—†ì–´ ì…ë ¥ ëª¨ë“œë¡œ ì „í™˜ë˜ì—ˆìŠµë‹ˆë‹¤(ë°ëª¨ìš©).")
        key2 = st.text_input("Google API Key ì…ë ¥", type="password").strip()
        return key2 if key2 else None


api_key = get_api_key()
if not api_key:
    st.warning("API Keyê°€ í•„ìš”í•©ë‹ˆë‹¤. Streamlit Cloud â†’ Secretsì— GOOGLE_API_KEY ì„¤ì •ì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
    st.stop()

try:
    client = genai.Client(api_key=api_key)
except Exception as e:
    st.error("Gemini Client ì´ˆê¸°í™” ì‹¤íŒ¨")
    st.exception(e)
    st.stop()

# ============================================================
# 3) PDF Parsing (Primary path for stability)
# ============================================================
def extract_text_from_pdf(uploaded_file) -> Tuple[str, int]:
    reader = PdfReader(uploaded_file)
    n_pages = len(reader.pages)

    parts = []
    for i in range(n_pages):
        try:
            t = reader.pages[i].extract_text() or ""
        except Exception:
            t = ""
        t = t.strip()
        if t:
            parts.append(f"[PAGE {i+1}]\n{t}")

    return "\n\n".join(parts).strip(), n_pages


def normalize_text(text: str) -> str:
    t = (text or "").replace("\r", "\n")
    while "\n\n\n" in t:
        t = t.replace("\n\n\n", "\n\n")
    return t.strip()


def trim_text(text: str, max_chars: int) -> str:
    if len(text) <= max_chars:
        return text
    return text[:max_chars] + "\n\n[...ì…ë ¥ ê¸¸ì´ ì œí•œìœ¼ë¡œ ì¼ë¶€ ìƒëµë¨...]"


# ============================================================
# 4) Gemini File Upload Fallback (optional)
# ============================================================
def upload_pdf_to_gemini_file_api(client, uploaded_file) -> Optional[object]:
    tmp_path = None
    try:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp:
            tmp.write(uploaded_file.getvalue())
            tmp_path = tmp.name

        with st.spinner("Gemini ì„œë²„ë¡œ PDF ì—…ë¡œë“œ ì¤‘(ëŒ€ì²´ ê²½ë¡œ)..."):
            file_ref = client.files.upload(path=tmp_path)

        return file_ref
    except Exception as e:
        st.error("íŒŒì¼ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        st.exception(e)
        return None
    finally:
        try:
            if tmp_path and os.path.exists(tmp_path):
                os.remove(tmp_path)
        except Exception:
            pass


# ============================================================
# 5) Gemini Call Wrapper (minimal retry)
# ============================================================
def generate_with_retry(model: str, contents, retries: int = 1, sleep_s: float = 0.6) -> str:
    last_err = None
    for attempt in range(retries + 1):
        try:
            resp = client.models.generate_content(model=model, contents=contents)
            return resp.text or ""
        except Exception as e:
            last_err = e
            if attempt < retries:
                time.sleep(sleep_s)
    raise last_err


# ============================================================
# 6) Build Prompts
# ============================================================
def build_prompt_summary(doc_text: str) -> str:
    return f"""
{PROMPT_COMMON_RULES}
{PROMPT_OPTIONS}
{PROMPT_SECTIONS_SUMMARY}

{TASK_SUMMARY}

[ë¬¸ì„œ í…ìŠ¤íŠ¸]
{doc_text}
""".strip()


def build_prompt_edu_qa(doc_text: str, num_q: int) -> str:
    spec = PROMPT_EDU_QA_SPEC.format(num_q=num_q)
    return f"""
{PROMPT_COMMON_RULES}
{PROMPT_OPTIONS}
{spec}

{TASK_EDU_QA}

[ë¬¸ì„œ í…ìŠ¤íŠ¸]
{doc_text}
""".strip()


def build_prompt_chat(doc_text: str, chat_history: List[Dict[str, str]], user_q: str) -> str:
    # íˆìŠ¤í† ë¦¬ëŠ” ê¸¸ì´ ì œí•œì´ í•„ìš” (ë„ˆë¬´ ê¸¸ë©´ API ë¬¸ì œ)
    # ìµœê·¼ Ní„´ë§Œ í¬í•¨
    last_turns = chat_history[-6:] if chat_history else []
    history_txt = "\n".join([f"{m['role']}: {m['content']}" for m in last_turns])

    return f"""
{PROMPT_COMMON_RULES}
{PROMPT_OPTIONS}
{PROMPT_CHAT_SPEC}

{TASK_CHAT}

[ëŒ€í™” ê¸°ë¡(ìµœê·¼)]
{history_txt}

[ì‚¬ìš©ì ì§ˆë¬¸]
{user_q}

[ë¬¸ì„œ í…ìŠ¤íŠ¸]
{doc_text}
""".strip()


# ============================================================
# 7) Sidebar UI (Korean)
# ============================================================
with st.sidebar:
    st.header("ì„¤ì • ë° ì—…ë¡œë“œ")

    model = st.selectbox("ëª¨ë¸ ì„ íƒ", ["gemini-2.5-flash", "gemini-2.5-pro", "gemini-2.0-flash"], index=0)

    max_chars = st.slider("ë¬¸ì„œ ì…ë ¥ ìƒí•œ(ë¬¸ì ìˆ˜)", 8000, 60000, 24000, 2000)

    st.subheader("ì²˜ë¦¬ ëª¨ë“œ")
    prefer_local_parse = st.checkbox("ë¡œì»¬ í…ìŠ¤íŠ¸ íŒŒì‹± ìš°ì„ (ê¶Œì¥)", value=True)
    allow_file_fallback = st.checkbox("í…ìŠ¤íŠ¸ ë¶€ì¡± ì‹œ ì—…ë¡œë“œ ëŒ€ì²´ ê²½ë¡œ í—ˆìš©", value=True)

    uploaded_file = st.file_uploader("KIHS ë³´ê³ ì„œ PDF ì—…ë¡œë“œ", type=["pdf"])

    st.subheader("êµìœ¡í˜• Q&A ì„¤ì •")
    num_q = st.slider("ë¬¸í•­ ìˆ˜", 3, 15, 7)

    st.markdown("### âš ï¸ ì•ˆë‚´")
    st.info(
        "- ìŠ¤ìº” PDF(ì´ë¯¸ì§€)ëŠ” í…ìŠ¤íŠ¸ ì¶”ì¶œì´ ê±°ì˜ ì•ˆ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
        "- ê·¸ ê²½ìš° ì—…ë¡œë“œ ëŒ€ì²´ ê²½ë¡œë¥¼ ì¼œë©´ íŒŒì¼ ê¸°ë°˜ ë¶„ì„ì„ ì‹œë„í•©ë‹ˆë‹¤.\n"
        "- ë„¤íŠ¸ì›Œí¬/ì •ì±…ì— ë”°ë¼ ì—…ë¡œë“œëŠ” ì‹¤íŒ¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
    )


# ============================================================
# 8) Session State
# ============================================================
if "last_uploaded" not in st.session_state:
    st.session_state.last_uploaded = None
if "parsed_text" not in st.session_state:
    st.session_state.parsed_text = ""
if "n_pages" not in st.session_state:
    st.session_state.n_pages = 0
if "file_ref" not in st.session_state:
    st.session_state.file_ref = None
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []  # list of {role, content}


# ============================================================
# 9) Main Logic
# ============================================================
if not uploaded_file:
    st.info("ì¢Œì¸¡ ì‚¬ì´ë“œë°”ì—ì„œ PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
    st.markdown("---")
    st.markdown("**ì˜ˆì‹œ íŒŒì¼:**")
    st.markdown("- 2021_KIHS_Water Resources Forum_Final Report.pdf")
    st.markdown("- 2022_KIHS_Water Resources Forum_Final Report.pdf")
    st.stop()

# ìƒˆ íŒŒì¼ì´ë©´ ìƒíƒœ ì´ˆê¸°í™”
if st.session_state.last_uploaded != uploaded_file.name:
    st.session_state.last_uploaded = uploaded_file.name
    st.session_state.parsed_text = ""
    st.session_state.n_pages = 0
    st.session_state.file_ref = None
    st.session_state.chat_history = []

# 1) ë¡œì»¬ íŒŒì‹±(ìš°ì„ )
MIN_TEXT_CHARS = 1200
if prefer_local_parse and not st.session_state.parsed_text:
    with st.spinner("PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ(ë¡œì»¬ íŒŒì‹±) ì¤‘..."):
        try:
            text, n_pages = extract_text_from_pdf(uploaded_file)
            text = normalize_text(text)
            st.session_state.parsed_text = text
            st.session_state.n_pages = n_pages
        except Exception as e:
            st.error("PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨")
            st.exception(e)

st.success(f"ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ: {uploaded_file.name}")
st.caption(f"í˜ì´ì§€ ìˆ˜: {st.session_state.n_pages} | ì¶”ì¶œ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(st.session_state.parsed_text):,} chars")

# 2) í…ìŠ¤íŠ¸ ë¶€ì¡±í•˜ë©´ ì—…ë¡œë“œ ëŒ€ì²´ ê²½ë¡œ(ì„ íƒ)
text_insufficient = len(st.session_state.parsed_text) < MIN_TEXT_CHARS
if text_insufficient and allow_file_fallback and st.session_state.file_ref is None:
    st.warning("í…ìŠ¤íŠ¸ ì¶”ì¶œì´ ë¶€ì¡±í•©ë‹ˆë‹¤(ìŠ¤ìº” PDF ê°€ëŠ¥). ì—…ë¡œë“œ ëŒ€ì²´ ê²½ë¡œë¥¼ ì‹œë„í•©ë‹ˆë‹¤.")
    st.session_state.file_ref = upload_pdf_to_gemini_file_api(client, uploaded_file)

# Tabs
tab1, tab2, tab3, tab4 = st.tabs(["ğŸ“„ ìš”ì•½ ë¦¬í¬íŠ¸", "ğŸ“ êµìœ¡í˜• Q&A", "ğŸ’¬ ì¶”ê°€ ì§ˆì˜", "ğŸ§¾ íŒŒì‹± í™•ì¸"])

with tab4:
    st.markdown("### ğŸ§¾ í…ìŠ¤íŠ¸ íŒŒì‹± í™•ì¸(ì¼ë¶€)")
    if st.session_state.parsed_text:
        st.text_area("ë¯¸ë¦¬ë³´ê¸°", trim_text(st.session_state.parsed_text, 4000), height=260)
    else:
        st.info("ì¶”ì¶œëœ í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. (ìŠ¤ìº” PDFì¼ ê°€ëŠ¥ì„±)")

# ------------------------------------------------------------
# Tab1: Summary Report
# ------------------------------------------------------------
with tab1:
    st.markdown("### ğŸ“‹ ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„±")
    btn_summary = st.button("ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„±", type="primary", key="btn_summary")
    if btn_summary:
        with st.spinner("ë¦¬í¬íŠ¸ ìƒì„± ì¤‘..."):
            try:
                if st.session_state.parsed_text and len(st.session_state.parsed_text) >= MIN_TEXT_CHARS:
                    doc_text = trim_text(st.session_state.parsed_text, max_chars=max_chars)
                    prompt = build_prompt_summary(doc_text)
                    out = generate_with_retry(model=model, contents=prompt, retries=1)
                    st.markdown(out)
                elif st.session_state.file_ref is not None:
                    prompt = (
                        f"{PROMPT_COMMON_RULES}\n{PROMPT_OPTIONS}\n{PROMPT_SECTIONS_SUMMARY}\n\n"
                        f"{TASK_SUMMARY}\n\n"
                        "â€» ë¬¸ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œì´ ë¶€ì¡±í•˜ì—¬ íŒŒì¼ ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤."
                    )
                    out = generate_with_retry(model=model, contents=[st.session_state.file_ref, prompt], retries=1)
                    st.markdown(out)
                else:
                    st.error("í…ìŠ¤íŠ¸ë„ ë¶€ì¡±í•˜ê³  ì—…ë¡œë“œ ëŒ€ì²´ ê²½ë¡œë„ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            except Exception as e:
                st.error("ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
                st.exception(e)

# ------------------------------------------------------------
# Tab2: Educational Q&A
# ------------------------------------------------------------
with tab2:
    st.markdown("### ğŸ“ êµìœ¡í˜• Q&A ìƒì„±")
    st.caption("ë¬¸ì„œ ê¸°ë°˜ìœ¼ë¡œ í•µì‹¬ ê°œë…/ë§¥ë½/ë°©ë²•/ê²°ê³¼/í•œê³„/ì‹¤ë¬´ ì ìš©ì„ í•™ìŠµí•˜ë„ë¡ ë¬¸ë‹µì„ êµ¬ì„±í•©ë‹ˆë‹¤.")

    btn_qa = st.button("êµìœ¡í˜• Q&A ìƒì„±", type="secondary", key="btn_qa")
    if btn_qa:
        with st.spinner("êµìœ¡í˜• Q&A ìƒì„± ì¤‘..."):
            try:
                if st.session_state.parsed_text and len(st.session_state.parsed_text) >= MIN_TEXT_CHARS:
                    doc_text = trim_text(st.session_state.parsed_text, max_chars=max_chars)
                    prompt = build_prompt_edu_qa(doc_text, num_q=num_q)
                    out = generate_with_retry(model=model, contents=prompt, retries=1)
                    st.markdown(out)
                elif st.session_state.file_ref is not None:
                    prompt = (
                        f"{PROMPT_COMMON_RULES}\n{PROMPT_OPTIONS}\n"
                        f"{PROMPT_EDU_QA_SPEC.format(num_q=num_q)}\n\n"
                        f"{TASK_EDU_QA}\n\n"
                        "â€» ë¬¸ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œì´ ë¶€ì¡±í•˜ì—¬ íŒŒì¼ ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤."
                    )
                    out = generate_with_retry(model=model, contents=[st.session_state.file_ref, prompt], retries=1)
                    st.markdown(out)
                else:
                    st.error("í…ìŠ¤íŠ¸ë„ ë¶€ì¡±í•˜ê³  ì—…ë¡œë“œ ëŒ€ì²´ ê²½ë¡œë„ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            except Exception as e:
                st.error("êµìœ¡í˜• Q&A ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
                st.exception(e)

# ------------------------------------------------------------
# Tab3: Chat / Follow-up queries
# ------------------------------------------------------------
with tab3:
    st.markdown("### ğŸ’¬ ì¶”ê°€ ì§ˆì˜ (ë¬¸ì„œ ê¸°ë°˜ Q&A)")
    st.caption("ë³´ê³ ì„œ ë‚´ìš©ì— ëŒ€í•´ ì¶”ê°€ ì§ˆë¬¸ì„ ì…ë ¥í•˜ë©´, ë¬¸ì„œ ê·¼ê±° ì¤‘ì‹¬ìœ¼ë¡œ ë‹µí•©ë‹ˆë‹¤.")

    # ëŒ€í™” í‘œì‹œ
    if st.session_state.chat_history:
        for m in st.session_state.chat_history:
            with st.chat_message("user" if m["role"] == "user" else "assistant"):
                st.markdown(m["content"])
    else:
        st.info("ì•„ì§ ëŒ€í™”ê°€ ì—†ìŠµë‹ˆë‹¤. ì•„ë˜ ì…ë ¥ì°½ì— ì§ˆë¬¸ì„ ì…ë ¥í•´ ë³´ì„¸ìš”.")

    user_q = st.chat_input("ì¶”ê°€ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: ì´ ë³´ê³ ì„œì˜ í•µì‹¬ ë°ì´í„°ëŠ” ë¬´ì—‡ì¸ê°€ìš”?)")

    if user_q:
        # store user msg
        st.session_state.chat_history.append({"role": "user", "content": user_q})

        with st.chat_message("user"):
            st.markdown(user_q)

        with st.spinner("ë‹µë³€ ìƒì„± ì¤‘..."):
            try:
                # í…ìŠ¤íŠ¸ ê¸°ë°˜ ìš°ì„ 
                if st.session_state.parsed_text and len(st.session_state.parsed_text) >= MIN_TEXT_CHARS:
                    doc_text = trim_text(st.session_state.parsed_text, max_chars=max_chars)
                    prompt = build_prompt_chat(doc_text, st.session_state.chat_history, user_q)
                    out = generate_with_retry(model=model, contents=prompt, retries=1)

                # ì—…ë¡œë“œ ëŒ€ì²´ ê²½ë¡œ
                elif st.session_state.file_ref is not None:
                    prompt = (
                        f"{PROMPT_COMMON_RULES}\n{PROMPT_OPTIONS}\n{PROMPT_CHAT_SPEC}\n\n"
                        f"{TASK_CHAT}\n\n"
                        f"[ì‚¬ìš©ì ì§ˆë¬¸]\n{user_q}\n\n"
                        "â€» ë¬¸ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œì´ ë¶€ì¡±í•˜ì—¬ íŒŒì¼ ê¸°ë°˜ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤."
                    )
                    out = generate_with_retry(model=model, contents=[st.session_state.file_ref, prompt], retries=1)
                else:
                    out = "í…ìŠ¤íŠ¸ë„ ë¶€ì¡±í•˜ê³  ì—…ë¡œë“œ ëŒ€ì²´ ê²½ë¡œë„ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. (ì˜µì…˜/ë„¤íŠ¸ì›Œí¬ í™•ì¸)"

                # store assistant msg
                st.session_state.chat_history.append({"role": "assistant", "content": out})

                with st.chat_message("assistant"):
                    st.markdown(out)

            except Exception as e:
                st.error("ì¶”ê°€ ì§ˆì˜ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
                st.exception(e)
